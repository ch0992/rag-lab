import os
import json
import httpx
from typing import List, Dict, Any
from config import settings
from utils.embeddings import get_embeddings
from utils.vector_store import VectorStore

class RAGService:
    def __init__(self):
        self.vector_store = VectorStore()
        self.base_url = settings.OLLAMA_BASE_URL
        self.model = settings.MODEL_NAME
        self.document_path = settings.DOCUMENT_PATH
        
    def load_all_documents(self) -> List[str]:
        """document í´ë”ì˜ ëª¨ë“  í…ìŠ¤íŠ¸ íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ ë²¡í„° DBì— ì €ì¥í•©ë‹ˆë‹¤."""
        loaded_files = []
        try:
            # ë¬¸ì„œ í´ë” ë‚´ ëª¨ë“  .txt íŒŒì¼ ê²€ìƒ‰
            for file_name in os.listdir(self.document_path):
                if not file_name.endswith('.txt'):
                    continue
                    
                file_path = os.path.join(self.document_path, file_name)
                collection_name = os.path.splitext(file_name)[0]
                
                # íŒŒì¼ ë‚´ìš© ì½ê¸°
                with open(file_path, 'r', encoding='utf-8') as f:
                    text_content = f.read().strip()
                    
                if text_content:
                    # ë²¡í„° DB ì €ì¥
                    self.vector_store.add_texts([text_content], collection_name)
                    loaded_files.append(file_name)
                    
            return loaded_files
            
        except Exception as e:
            print(f"Error loading documents: {e}")
            return []

    async def query_ollama(self, prompt: str) -> str:
        try:
            # íƒ€ì„ì•„ì›ƒ ì„¤ì • ì¦ê°€
            timeout = httpx.Timeout(
                timeout=120.0,     # ì „ì²´ íƒ€ì„ì•„ì›ƒ
                connect=30.0,     # ì—°ê²° íƒ€ì„ì•„ì›ƒ
                read=120.0,       # ì½ê¸° íƒ€ì„ì•„ì›ƒ
                write=30.0,       # ì“°ê¸° íƒ€ì„ì•„ì›ƒ
                pool=30.0         # í’€ íƒ€ì„ì•„ì›ƒ
            )
            
            async with httpx.AsyncClient(timeout=timeout) as client:
                response = await client.post(
                    f"{self.base_url}/api/generate",
                    json={
                        "model": self.model,
                        "prompt": prompt,
                        "stream": False,  # ìŠ¤íŠ¸ë¦¬ë° ë¹„í™œì„±í™”
                        "options": {
                            "temperature": 0.7,
                            "top_p": 0.9,
                            "top_k": 40
                        }
                    }
                )

                
                if response.status_code != 200:
                    print(f"Error response from Ollama API: {response.text}")
                    return "âš ï¸ Ollama API ì˜¤ë¥˜"
                
                json_response = response.json()

                
                if 'response' not in json_response:
    
                    return "âš ï¸ Ollama ì‘ë‹µ ì˜¤ë¥˜"
                
                response_text = json_response['response']
                
                # think íƒœê·¸ì™€ ê·¸ ë‚´ìš© ì œê±°
                if '<think>' in response_text:
                    parts = response_text.split('<think>')
                    for i in range(1, len(parts)):
                        if '</think>' in parts[i]:
                            parts[i] = parts[i].split('</think>', 1)[1]
                    response_text = ''.join(parts).strip()
                
                # ì‘ë‹µì—ì„œ '[' ë¡œ ì‹œì‘í•˜ëŠ” í—¤ë” ë¶€ë¶„ ì œê±°
                if '[' in response_text:
                    response_text = response_text.split(']')[-1].strip()
                
                # ì¶”ê°€ ê°œí–‰ ì œê±° ë° í¬ë§· ì •ë¦¬
                lines = [line.strip() for line in response_text.split('\n') if line.strip()]
                
                # ì²˜ìŒ ì¤„ì€ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ê³ , ë²ˆí˜¸ í•­ëª©ë§Œ êµ¬ë¶„
                if not lines:
                    return "âš ï¸ ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."
                    
                formatted_response = lines[0]
                for line in lines[1:]:
                    if line.startswith(('1)', '2)', '3)', '4)', '5)', '6)', '7)', '8)', '9)')): 
                        formatted_response += '\n\n' + line
                    else:
                        formatted_response += '\n' + line
                
                return formatted_response
                
        except Exception as e:
            import traceback
            print(f"Error in query_ollama: {e}")
            print(f"Traceback: {traceback.format_exc()}")
            return "âš ï¸ Ollama API ì˜¤ë¥˜"

    async def run_rag_query(self, collection_name: str, query: str) -> str:
        try:
            # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
            query_embedding = get_embeddings([query])
            # ì§€ì •ëœ ì½œë ‰ì…˜ì˜ ë¬¸ì„œ ê²€ìƒ‰
            similar_docs = self.vector_store.similarity_search(query_embedding, collection_name)
            if not similar_docs:
                return "ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤."
            
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = f"""ì—­í• : ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ë¬¸ì„œë“¤ì—ì„œ ëª¨ë“  ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì•„ ì¢…í•©ì ìœ¼ë¡œ ë‹µë³€í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.

ë¬¸ì„œ ë‚´ìš©:
{similar_docs}

ì§ˆë¬¸: {query}

ì¤‘ìš” ì§€ì¹¨:
1. ëª¨ë“  ë¬¸ì„œì˜ ë‚´ìš©ì„ ê²€í† í•˜ì—¬ ê´€ë ¨ëœ ì •ë³´ë¥¼ ëª¨ë‘ ì°¾ì•„ì£¼ì„¸ìš”.
2. ê° ë¬¸ì„œì˜ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ í•˜ë‚˜ì˜ ì™„ì„±ëœ ë‹µë³€ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.
3. ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.
4. ì™¸ë¶€ ì§€ì‹ì´ë‚˜ ì¶”ë¡ ì€ í•˜ì§€ ë§ˆì„¸ìš”.
5. ì˜ì–´ë‚˜ íŠ¹ìˆ˜ë¬¸ìëŠ” ìµœì†Œí•œìœ¼ë¡œ ì‚¬ìš©í•˜ì„¸ìš”.
6. ì—¬ëŸ¬ ë¬¸ì„œì˜ ì •ë³´ê°€ ìˆë‹¤ë©´ ëª¨ë‘ í¬í•¨í•´ì„œ ë‹µë³€í•´ì£¼ì„¸ìš”.
7. ë‹µë³€ì€ ê°„ê²°í•˜ë©´ì„œë„ í¬ê´„ì ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
8. ë¬¸ì„œì—ì„œ ê´€ë ¨ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´ 'ì£¼ì–´ì§„ ë¬¸ì„œì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'ë¼ê³ ë§Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
9. ë‹µë³€ ì‹œì‘ì—ëŠ” 'ğŸ’¬ ë‹µë³€: 'ì„ ë¶™ì—¬ì£¼ì„¸ìš”.
"""
            # í”„ë¡¬í”„íŠ¸ ì¶œë ¥ ì œê±°
            
            # Ollama API í˜¸ì¶œ
            response = await self.query_ollama(prompt)
            return response
            
        except Exception as e:
            import traceback
            print(f"Error in run_rag_query: {e}")
            print(f"Traceback: {traceback.format_exc()}")
            return "ì¿¼ë¦¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
