{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¯ Step 04: ë°ì´í„°ë² ì´ìŠ¤ ë©”íƒ€ë°ì´í„° RAG ì‹œìŠ¤í…œ\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ ë©”íƒ€ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ì‹¤ìš©ì ì¸ RAG ì‹œìŠ¤í…œì„ êµ¬í˜„í•©ë‹ˆë‹¤.\n",
    "ì‚¬ìš©ìëŠ” ìì—°ì–´ë¡œ ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¡°ì— ëŒ€í•´ ì§ˆë¬¸í•˜ê³ , ì‹œìŠ¤í…œì€ ë©”íƒ€ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.\n",
    "\n",
    "## ğŸ“š 1ë‹¨ê³„: í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "\n",
    "ì´ì „ ë‹¨ê³„ì˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ë”í•´ ë‹¤ìŒ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ ì¶”ê°€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤:\n",
    "- pandas: CSV íŒŒì¼ ì½ê¸° ë° ë°ì´í„° ì²˜ë¦¬\n",
    "- json: ìƒ˜í”Œ ê°’ê³¼ í†µê³„ ë°ì´í„° ì²˜ë¦¬\n",
    "- typing: íƒ€ì… íŒíŠ¸ ì œê³µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê¸°ë³¸ ì‹œìŠ¤í…œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import os\n",
    "import json\n",
    "from typing import List, Dict\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ë°ì´í„° ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import pandas as pd\n",
    "\n",
    "# Elasticsearch ê´€ë ¨\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "# LangChain ê´€ë ¨\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import ElasticsearchStore\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š 2ë‹¨ê³„: ë©”íƒ€ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
    "\n",
    "sample_metadata.csv íŒŒì¼ì—ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤:\n",
    "- í…Œì´ë¸”ëª…\n",
    "- ì»¬ëŸ¼ëª…\n",
    "- ë°ì´í„° íƒ€ì…\n",
    "- ì„¤ëª…\n",
    "- ìƒ˜í”Œ ê°’\n",
    "- í†µê³„ ì •ë³´\n",
    "\n",
    "ì´ ì •ë³´ë¥¼ ì½ì–´ì„œ RAG ì‹œìŠ¤í…œì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë³€í™˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
    "metadata_file = \"../data/sample_metadata.csv\"\n",
    "\n",
    "# CSV íŒŒì¼ ì½ê¸°\n",
    "df = pd.read_csv(metadata_file)\n",
    "\n",
    "# ë©”íƒ€ë°ì´í„°ë¥¼ ë¬¸ì„œí™”ëœ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜\n",
    "def format_metadata_to_text(row) -> str:\n",
    "    # JSON í˜•ì‹ì˜ ë¬¸ìì—´ì„ íŒŒì´ì¬ ê°ì²´ë¡œ ë³€í™˜\n",
    "    sample_values = json.loads(row['sample_values'].replace(\"'\", '\"'))\n",
    "    statistics = json.loads(row['statistics'].replace(\"'\", '\"'))\n",
    "    \n",
    "    # í†µê³„ ì •ë³´ë¥¼ ì½ê¸° ì‰¬ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "    stats_text = []\n",
    "    for key, value in statistics.items():\n",
    "        if key == 'null_count':\n",
    "            stats_text.append(f\"NULL ê°’ ê°œìˆ˜: {value}\")\n",
    "        elif key == 'distinct_count':\n",
    "            stats_text.append(f\"ê³ ìœ  ê°’ ê°œìˆ˜: {value}\")\n",
    "        elif key in ['min', 'max']:\n",
    "            stats_text.append(f\"{key}: {value}\")\n",
    "    \n",
    "    # ì „ì²´ í…ìŠ¤íŠ¸ êµ¬ì„±\n",
    "    return f\"í…Œì´ë¸” '{row['table_name']}'ì˜ '{row['column_name']}' ì»¬ëŸ¼:\\n\" + \\\n",
    "           f\"- ë°ì´í„° íƒ€ì…: {row['data_type']}\\n\" + \\\n",
    "           f\"- ì„¤ëª…: {row['description']}\\n\" + \\\n",
    "           f\"- ìƒ˜í”Œ ê°’: {', '.join(map(str, sample_values))}\\n\" + \\\n",
    "           f\"- í†µê³„: {', '.join(stats_text)}\"\n",
    "\n",
    "# ê° í–‰ì„ ë¬¸ì„œí™”ëœ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
    "documents = df.apply(format_metadata_to_text, axis=1).tolist()\n",
    "\n",
    "# ë³€í™˜ëœ ë¬¸ì„œ ê°œìˆ˜ ì¶œë ¥\n",
    "print(f\"âœ… {len(documents)}ê°œì˜ ë©”íƒ€ë°ì´í„° ë¬¸ì„œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# ì²« ë²ˆì§¸ ë¬¸ì„œ ì˜ˆì‹œ ì¶œë ¥\n",
    "print(\"\\nğŸ“ ë¬¸ì„œ ì˜ˆì‹œ:\")\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”Œ 3ë‹¨ê³„: Elasticsearch ì—°ê²°\n",
    "\n",
    "ì´ì „ ë‹¨ê³„ì™€ ë™ì¼í•˜ê²Œ Elasticsearchì— ì—°ê²°í•©ë‹ˆë‹¤.\n",
    "ì´ë²ˆì—ëŠ” ë©”íƒ€ë°ì´í„° ì „ìš© ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•  ê²ƒì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elasticsearch í´ë¼ì´ì–¸íŠ¸ ì„¤ì •\n",
    "es = Elasticsearch(\n",
    "    os.getenv('ELASTICSEARCH_URL'),\n",
    "    basic_auth=(\n",
    "        os.getenv('ELASTICSEARCH_USERNAME'),\n",
    "        os.getenv('ELASTICSEARCH_PASSWORD')\n",
    "    ),\n",
    "    verify_certs=False\n",
    ")\n",
    "\n",
    "# ì—°ê²° í™•ì¸\n",
    "if es.ping():\n",
    "    print(\"âœ… Elasticsearch ì—°ê²° ì„±ê³µ!\")\n",
    "else:\n",
    "    print(\"âŒ Elasticsearch ì—°ê²° ì‹¤íŒ¨!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”„ 4ë‹¨ê³„: ë©”íƒ€ë°ì´í„° ë²¡í„° ì €ì¥ì†Œ ì„¤ì •\n",
    "\n",
    "ë©”íƒ€ë°ì´í„° ë¬¸ì„œë“¤ì„ ë²¡í„°ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "ì´ì „ê³¼ ë‹¬ë¦¬ ì´ë²ˆì—ëŠ” ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¡°ì— ëŒ€í•œ ì •ë³´ë¥¼ ì €ì¥í•˜ë¯€ë¡œ,\n",
    "ë” ì •í™•í•œ ê²€ìƒ‰ê³¼ ë‹µë³€ì´ ê°€ëŠ¥í•´ì§‘ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# ë©”íƒ€ë°ì´í„° ì „ìš© ë²¡í„° ì €ì¥ì†Œ ì„¤ì •\n",
    "index_name = \"metadata-rag\"  # ìƒˆë¡œìš´ ì¸ë±ìŠ¤ ì´ë¦„\n",
    "vector_store = ElasticsearchStore(\n",
    "    es_connection=es,\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "# ë©”íƒ€ë°ì´í„° ë¬¸ì„œë“¤ì„ ë²¡í„°ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥\n",
    "vector_store.add_texts(documents)\n",
    "print(f\"âœ… {len(documents)}ê°œì˜ ë©”íƒ€ë°ì´í„° ë¬¸ì„œê°€ ë²¡í„° ì €ì¥ì†Œì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¤– 5ë‹¨ê³„: ë©”íƒ€ë°ì´í„° RAG ì‹œìŠ¤í…œ êµ¬í˜„\n",
    "\n",
    "ì´ì œ ë°ì´í„°ë² ì´ìŠ¤ ë©”íƒ€ë°ì´í„°ì— íŠ¹í™”ëœ RAG ì‹œìŠ¤í…œì„ êµ¬í˜„í•©ë‹ˆë‹¤.\n",
    "ì‚¬ìš©ìëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì§ˆë¬¸ë“¤ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
    "- íŠ¹ì • í…Œì´ë¸”ì˜ êµ¬ì¡°\n",
    "- íŠ¹ì • ì»¬ëŸ¼ì˜ ë°ì´í„° íƒ€ì…\n",
    "- ì»¬ëŸ¼ì˜ ì„¤ëª…ê³¼ ìš©ë„\n",
    "- ë°ì´í„°ì˜ íŠ¹ì„±ê³¼ í†µê³„ ì •ë³´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatGPT ëª¨ë¸ ì´ˆê¸°í™”\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# ë©”íƒ€ë°ì´í„° ì§ˆì˜ì‘ë‹µ ì²´ì¸ ìƒì„±\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vector_store.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¬ 6ë‹¨ê³„: ë©”íƒ€ë°ì´í„° ì§ˆì˜ì‘ë‹µ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "ì´ì œ ë‹¤ì–‘í•œ ì§ˆë¬¸ì„ í†µí•´ ë©”íƒ€ë°ì´í„° RAG ì‹œìŠ¤í…œì„ í…ŒìŠ¤íŠ¸í•´ë´…ë‹ˆë‹¤.\n",
    "ì‹œìŠ¤í…œì€ ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ íŒŒì•…í•˜ê³ , ê´€ë ¨ëœ ë©”íƒ€ë°ì´í„°ë¥¼ ê²€ìƒ‰í•˜ì—¬\n",
    "ì •í™•í•˜ê³  ìƒì„¸í•œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸í•  ì§ˆë¬¸ë“¤\n",
    "questions = [\n",
    "    \"customer_orders í…Œì´ë¸”ì˜ êµ¬ì¡°ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.\",\n",
    "    \"ì£¼ë¬¸ ê¸ˆì•¡ì˜ ë²”ìœ„ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\",\n",
    "    \"ì£¼ë¬¸ ìƒíƒœëŠ” ì–´ë–¤ ê°’ë“¤ì´ ê°€ëŠ¥í•œê°€ìš”?\",\n",
    "    \"ê³ ê°ì˜ ì´ë©”ì¼ ì •ë³´ëŠ” ì–´ë–¤ í…Œì´ë¸”ì— ì €ì¥ë˜ë‚˜ìš”?\"\n",
    "]\n",
    "\n",
    "# ê° ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„±\n",
    "for question in questions:\n",
    "    print(f\"\\nì§ˆë¬¸: {question}\")\n",
    "    print(f\"ë‹µë³€: {qa_chain.run(question)}\")\n",
    "    print(\"-\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
