{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ”¡ Step 05: OpenAI Embeddingìœ¼ë¡œ í…ìŠ¤íŠ¸ ë²¡í„°í™”\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” ì´ì „ ë‹¨ê³„ì—ì„œ ì „ì²˜ë¦¬í•œ ë¬¸ì„œë“¤ì„ OpenAIì˜ Embedding APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë²¡í„°í™”í•©ë‹ˆë‹¤.\n",
    "\n",
    "## ğŸ“ ì£¼ìš” ë‚´ìš©\n",
    "1. OpenAI API ì„¤ì •\n",
    "2. í…ìŠ¤íŠ¸ ì„ë² ë”© í•¨ìˆ˜ êµ¬í˜„\n",
    "3. ë¬¸ì„œ ë²¡í„°í™” ë° ì €ì¥\n",
    "4. ë²¡í„° í’ˆì§ˆ í™•ì¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "\n",
    "í…ìŠ¤íŠ¸ ë²¡í„°í™”ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ ì„í¬íŠ¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ ì´ì „ ë‹¨ê³„ì˜ ì „ì²˜ë¦¬ëœ ë¬¸ì„œ ë¡œë“œ\n",
    "\n",
    "Step 04ì—ì„œ ì €ì¥í•œ ì „ì²˜ë¦¬ëœ ë¬¸ì„œë“¤ì„ ë¡œë“œí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì „ì²˜ë¦¬ëœ ë¬¸ì„œë¥¼ ë¡œë“œí•©ë‹ˆë‹¤\n",
    "with open('../data/processed/documents.json', 'r', encoding='utf-8') as f:\n",
    "    documents = json.load(f)\n",
    "\n",
    "print(f\"ë¡œë“œëœ ë¬¸ì„œ ìˆ˜: {len(documents)}\")\n",
    "print(\"\\në¬¸ì„œ ì˜ˆì‹œ:\")\n",
    "print(json.dumps(documents[0], indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ í…ìŠ¤íŠ¸ ì„ë² ë”© í•¨ìˆ˜ êµ¬í˜„\n",
    "\n",
    "OpenAIì˜ text-embedding-ada-002 ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°í™”í•˜ëŠ” í•¨ìˆ˜ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text: str) -> List[float]:\n",
    "    \"\"\"\n",
    "    OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ì˜ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        text (str): ì„ë² ë”©í•  í…ìŠ¤íŠ¸\n",
    "        \n",
    "    Returns:\n",
    "        List[float]: 1536ì°¨ì›ì˜ ì„ë² ë”© ë²¡í„°\n",
    "    \"\"\"\n",
    "    response = client.embeddings.create(\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        input=text\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "def batch_get_embeddings(texts: List[str], batch_size: int = 100) -> List[List[float]]:\n",
    "    \"\"\"\n",
    "    ì—¬ëŸ¬ í…ìŠ¤íŠ¸ì˜ ì„ë² ë”©ì„ ë°°ì¹˜ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        texts (List[str]): ì„ë² ë”©í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸\n",
    "        batch_size (int): ë°°ì¹˜ í¬ê¸°\n",
    "        \n",
    "    Returns:\n",
    "        List[List[float]]: ì„ë² ë”© ë²¡í„° ë¦¬ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"ì„ë² ë”© ìƒì„± ì¤‘\"):\n",
    "        batch = texts[i:i + batch_size]\n",
    "        response = client.embeddings.create(\n",
    "            model=\"text-embedding-ada-002\",\n",
    "            input=batch\n",
    "        )\n",
    "        batch_embeddings = [data.embedding for data in response.data]\n",
    "        embeddings.extend(batch_embeddings)\n",
    "        \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ ë¬¸ì„œ ë²¡í„°í™”\n",
    "\n",
    "ì „ì²´ ë¬¸ì„œë¥¼ ë²¡í„°í™”í•˜ê³  ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¬¸ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "texts = [doc['content'] for doc in documents]\n",
    "\n",
    "# ì„ë² ë”© ìƒì„±\n",
    "embeddings = batch_get_embeddings(texts)\n",
    "\n",
    "# ì„ë² ë”©ì„ ë¬¸ì„œì— ì¶”ê°€\n",
    "for doc, embedding in zip(documents, embeddings):\n",
    "    doc['embedding'] = embedding\n",
    "\n",
    "# ë²¡í„°í™”ëœ ë¬¸ì„œ ì €ì¥\n",
    "output_path = '../data/processed/documents_with_embeddings.json'\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(documents, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"ë²¡í„°í™”ëœ ë¬¸ì„œê°€ {output_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ ë²¡í„° í’ˆì§ˆ í™•ì¸\n",
    "\n",
    "ìƒì„±ëœ ì„ë² ë”©ì˜ í’ˆì§ˆì„ ê°„ë‹¨íˆ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(v1: List[float], v2: List[float]) -> float:\n",
    "    \"\"\"\n",
    "    ë‘ ë²¡í„° ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    dot_product = np.dot(v1, v2)\n",
    "    norm1 = np.linalg.norm(v1)\n",
    "    norm2 = np.linalg.norm(v2)\n",
    "    return dot_product / (norm1 * norm2)\n",
    "\n",
    "# ìƒ˜í”Œ ë¬¸ì„œ ì„ íƒ\n",
    "sample_doc = documents[0]\n",
    "sample_embedding = sample_doc['embedding']\n",
    "\n",
    "# ë‹¤ë¥¸ ë¬¸ì„œë“¤ê³¼ì˜ ìœ ì‚¬ë„ ê³„ì‚°\n",
    "similarities = []\n",
    "for doc in documents[1:10]:  # ì²˜ìŒ 10ê°œ ë¬¸ì„œë§Œ ë¹„êµ\n",
    "    sim = cosine_similarity(sample_embedding, doc['embedding'])\n",
    "    similarities.append({\n",
    "        'content': doc['content'][:100] + '...',  # ë‚´ìš© ì¼ë¶€ë§Œ í‘œì‹œ\n",
    "        'similarity': sim\n",
    "    })\n",
    "\n",
    "# ìœ ì‚¬ë„ ê²°ê³¼ ì¶œë ¥\n",
    "print(\"ê¸°ì¤€ ë¬¸ì„œ:\")\n",
    "print(sample_doc['content'][:100] + '...\\n')\n",
    "\n",
    "print(\"ìœ ì‚¬ë„ê°€ ë†’ì€ ë¬¸ì„œë“¤:\")\n",
    "for item in sorted(similarities, key=lambda x: x['similarity'], reverse=True)[:3]:\n",
    "    print(f\"\\nìœ ì‚¬ë„: {item['similarity']:.4f}\")\n",
    "    print(f\"ë‚´ìš©: {item['content']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ ì •ë¦¬\n",
    "\n",
    "1. OpenAIì˜ text-embedding-ada-002 ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œë¥¼ ë²¡í„°í™”í–ˆìŠµë‹ˆë‹¤.\n",
    "2. ë°°ì¹˜ ì²˜ë¦¬ë¥¼ í†µí•´ íš¨ìœ¨ì ìœ¼ë¡œ ì„ë² ë”©ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.\n",
    "3. ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ í†µí•´ ë²¡í„°ì˜ í’ˆì§ˆì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ë‹¤ìŒ ë‹¨ê³„ì—ì„œëŠ” ì´ ë²¡í„°í™”ëœ ë¬¸ì„œë“¤ì„ Elasticsearchì— ì €ì¥í•˜ê³  ê²€ìƒ‰ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
