{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ Step 06: RAG ì‹œìŠ¤í…œ ê³ ë„í™”\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” ê¸°ì¡´ RAG ì‹œìŠ¤í…œì„ ê°œì„ í•˜ì—¬ ë” ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•˜ë„ë¡ ë§Œë“¤ì–´ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "ì£¼ìš” ê°œì„  ì‚¬í•­:\n",
    "1. í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§\n",
    "2. ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ ê°œì„ \n",
    "3. ë‹µë³€ í’ˆì§ˆ í–¥ìƒ\n",
    "\n",
    "## ğŸ“š 1ë‹¨ê³„: í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "\n",
    "ê¸°ì¡´ ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ì¶”ê°€ë¡œ ë‹¤ìŒ ê¸°ëŠ¥ë“¤ì„ í™œìš©í•©ë‹ˆë‹¤:\n",
    "- LangChainì˜ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "- ë‹µë³€ ìƒì„±ì„ ìœ„í•œ ê³ ê¸‰ ì²´ì¸\n",
    "- ì»¨í…ìŠ¤íŠ¸ ì²˜ë¦¬ë¥¼ ìœ„í•œ ìœ í‹¸ë¦¬í‹°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import List, Dict\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "\n",
    "# Elasticsearch ê´€ë ¨\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "# LangChain ê´€ë ¨\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import ElasticsearchStore\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ 2ë‹¨ê³„: ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜\n",
    "\n",
    "ë” ì •í™•í•˜ê³  êµ¬ì¡°í™”ëœ ë‹µë³€ì„ ìœ„í•´ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ê°œì„ í•©ë‹ˆë‹¤.\n",
    "ì´ë¥¼ í†µí•´ ì‹œìŠ¤í…œì´ ë” ì¼ê´€ë˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë©”íƒ€ë°ì´í„° ì§ˆì˜ì‘ë‹µì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "metadata_qa_template = \"\"\"\n",
    "ë‹¹ì‹ ì€ ë°ì´í„°ë² ì´ìŠ¤ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ë‹µë³€ ì‹œ ë‹¤ìŒ ê·œì¹™ì„ ë”°ë¼ì£¼ì„¸ìš”:\n",
    "1. í…Œì´ë¸”ì´ë‚˜ ì»¬ëŸ¼ëª…ì´ ë‚˜ì˜¤ë©´ `ë°±í‹±`ìœ¼ë¡œ ê°•ì¡°í•´ì£¼ì„¸ìš”.\n",
    "2. ë°ì´í„° íƒ€ì…ì´ë‚˜ ì œì•½ì¡°ê±´ì€ ëª…í™•í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
    "3. ê°€ëŠ¥í•œ ê²½ìš° ì˜ˆì‹œ ê°’ì„ í¬í•¨í•´ì£¼ì„¸ìš”.\n",
    "4. í†µê³„ ì •ë³´ê°€ ìˆë‹¤ë©´ í•¨ê»˜ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ì»¨í…ìŠ¤íŠ¸:\n",
    "{context}\n",
    "\n",
    "ì§ˆë¬¸: {question}\n",
    "\n",
    "ë‹µë³€: \"\"\"\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
    "QA_PROMPT = PromptTemplate(\n",
    "    template=metadata_qa_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”„ 3ë‹¨ê³„: ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ ê°œì„ \n",
    "\n",
    "ê²€ìƒ‰ëœ ë¬¸ì„œì˜ ê´€ë ¨ì„±ì„ ë†’ì´ê³ , ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ë¥¼ ìœ ì§€í•˜ì—¬\n",
    "ë” ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ê°€ ê°€ëŠ¥í•˜ë„ë¡ ê°œì„ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elasticsearch ì—°ê²° ì„¤ì •\n",
    "es = Elasticsearch(\n",
    "    os.getenv('ELASTICSEARCH_URL'),\n",
    "    basic_auth=(\n",
    "        os.getenv('ELASTICSEARCH_USERNAME'),\n",
    "        os.getenv('ELASTICSEARCH_PASSWORD')\n",
    "    ),\n",
    "    verify_certs=False\n",
    ")\n",
    "\n",
    "# ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# ê°œì„ ëœ ë²¡í„° ì €ì¥ì†Œ ì„¤ì •\n",
    "vector_store = ElasticsearchStore(\n",
    "    es_connection=es,\n",
    "    index_name=\"metadata-rag\",\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "# ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•  ë©”ëª¨ë¦¬ ì´ˆê¸°í™”\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "# ChatGPT ëª¨ë¸ ì´ˆê¸°í™” (temperature ì¡°ì •)\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.3)\n",
    "\n",
    "# ê°œì„ ëœ QA ì²´ì¸ ìƒì„±\n",
    "qa_chain = load_qa_chain(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    prompt=QA_PROMPT,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” 4ë‹¨ê³„: ê°œì„ ëœ ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„±\n",
    "\n",
    "ê²€ìƒ‰ ê²°ê³¼ì˜ í’ˆì§ˆì„ ë†’ì´ê³ , ë” ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€ì„ ìƒì„±í•˜ëŠ”\n",
    "í•¨ìˆ˜ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_enhanced_answer(question: str, retriever=vector_store.as_retriever(search_kwargs={\"k\": 3})) -> str:\n",
    "    \"\"\"\n",
    "    ê°œì„ ëœ ë‹µë³€ ìƒì„± í•¨ìˆ˜\n",
    "    \n",
    "    Args:\n",
    "        question: ì‚¬ìš©ì ì§ˆë¬¸\n",
    "        retriever: ë¬¸ì„œ ê²€ìƒ‰ê¸°\n",
    "    \n",
    "    Returns:\n",
    "        str: ìƒì„±ëœ ë‹µë³€\n",
    "    \"\"\"\n",
    "    # ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰\n",
    "    docs = retriever.get_relevant_documents(question)\n",
    "    \n",
    "    # ë¬¸ì„œê°€ ì—†ëŠ” ê²½ìš° ì²˜ë¦¬\n",
    "    if not docs:\n",
    "        return \"ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "    \n",
    "    # ì»¨í…ìŠ¤íŠ¸ ê²°í•©\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "    \n",
    "    # QA ì²´ì¸ìœ¼ë¡œ ë‹µë³€ ìƒì„±\n",
    "    result = qa_chain({\"input_documents\": docs, \"question\": question})\n",
    "    \n",
    "    return result[\"output_text\"]\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸\n",
    "test_questions = [\n",
    "    \"customer_orders í…Œì´ë¸”ì˜ total_amount ì»¬ëŸ¼ì— ëŒ€í•´ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.\",\n",
    "    \"ì£¼ë¬¸ ìƒíƒœëŠ” ì–´ë–¤ ê°’ë“¤ì´ ê°€ëŠ¥í•˜ê³ , NULLì´ í—ˆìš©ë˜ë‚˜ìš”?\",\n",
    "    \"ê³ ê° ì •ë³´ëŠ” ì–´ë–¤ í…Œì´ë¸”ì— ì–´ë–¤ í˜•íƒœë¡œ ì €ì¥ë˜ë‚˜ìš”?\"\n",
    "]\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "print(\"ğŸ§ª ê°œì„ ëœ RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸\\n\")\n",
    "for question in test_questions:\n",
    "    print(f\"ì§ˆë¬¸: {question}\")\n",
    "    print(f\"ë‹µë³€: {get_enhanced_answer(question)}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š 5ë‹¨ê³„: ì„±ëŠ¥ í‰ê°€\n",
    "\n",
    "ê°œì„ ëœ ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ì§€í‘œë“¤ì„ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_answer(question: str, answer: str) -> Dict[str, bool]:\n",
    "    \"\"\"\n",
    "    ë‹µë³€ í’ˆì§ˆ í‰ê°€ í•¨ìˆ˜\n",
    "    \n",
    "    Args:\n",
    "        question: ì§ˆë¬¸\n",
    "        answer: ìƒì„±ëœ ë‹µë³€\n",
    "    \n",
    "    Returns:\n",
    "        Dict[str, bool]: í‰ê°€ ê²°ê³¼\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"ë°±í‹± ì‚¬ìš©\": \"`\" in answer,  # í…Œì´ë¸”/ì»¬ëŸ¼ëª… ê°•ì¡°\n",
    "        \"ì˜ˆì‹œ í¬í•¨\": \"[\" in answer or \"ì˜ˆ:\" in answer,  # ì˜ˆì‹œ ê°’ í¬í•¨\n",
    "        \"í†µê³„ ì •ë³´\": \"ìµœì†Œ\" in answer or \"ìµœëŒ€\" in answer or \"ê°œìˆ˜\" in answer,  # í†µê³„ ì •ë³´ í¬í•¨\n",
    "        \"ëª…í™•í•œ ì„¤ëª…\": len(answer.split()) >= 20  # ì¶©ë¶„í•œ ì„¤ëª… ê¸¸ì´\n",
    "    }\n",
    "\n",
    "# í‰ê°€ ì‹¤í–‰\n",
    "print(\"ğŸ“Š ë‹µë³€ í’ˆì§ˆ í‰ê°€\\n\")\n",
    "for question in test_questions:\n",
    "    answer = get_enhanced_answer(question)\n",
    "    results = evaluate_answer(question, answer)\n",
    "    \n",
    "    print(f\"ì§ˆë¬¸: {question}\")\n",
    "    for metric, passed in results.items():\n",
    "        status = \"âœ…\" if passed else \"âŒ\"\n",
    "        print(f\"{status} {metric}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ ì£¼ìš” ê°œì„ ì‚¬í•­\n",
    "\n",
    "1. í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§\n",
    "   - êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "   - ì¼ê´€ëœ í¬ë§·íŒ… ê·œì¹™\n",
    "   - ìƒì„¸í•œ ë‹µë³€ ê°€ì´ë“œë¼ì¸\n",
    "\n",
    "2. ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬\n",
    "   - ëŒ€í™” ê¸°ë¡ ìœ ì§€\n",
    "   - ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ ê°œì„ \n",
    "   - ë¬¸ì„œ ê²°í•© ë¡œì§ ê°œì„ \n",
    "\n",
    "3. ë‹µë³€ í’ˆì§ˆ\n",
    "   - í¬ë§·íŒ… ì¼ê´€ì„±\n",
    "   - ì˜ˆì‹œ ê°’ í¬í•¨\n",
    "   - í†µê³„ ì •ë³´ í™œìš©\n",
    "\n",
    "4. ì„±ëŠ¥ í‰ê°€\n",
    "   - ê°ê´€ì  í‰ê°€ ì§€í‘œ\n",
    "   - í’ˆì§ˆ ëª¨ë‹ˆí„°ë§\n",
    "   - ê°œì„  í¬ì¸íŠ¸ ì‹ë³„\n",
    "\n",
    "ì´ëŸ¬í•œ ê°œì„ ì„ í†µí•´ ë” ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
