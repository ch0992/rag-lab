{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔍 Step 03: 기본 RAG 시스템 구현\n",
    "\n",
    "이 노트북에서는 Elasticsearch를 사용하여 기본적인 RAG(Retrieval-Augmented Generation) 시스템을 구현합니다.\n",
    "RAG는 다음과 같은 단계로 동작합니다:\n",
    "\n",
    "1. 문서를 벡터로 변환하여 저장 (임베딩)\n",
    "2. 질문이 들어오면 관련된 문서를 검색\n",
    "3. 검색된 문서를 참고하여 AI가 답변 생성\n",
    "\n",
    "## 📚 1단계: 필요한 라이브러리 임포트\n",
    "\n",
    "각 라이브러리의 역할:\n",
    "- dotenv: 환경 변수 관리\n",
    "- elasticsearch: 벡터 데이터베이스 연결\n",
    "- langchain: RAG 시스템 구현을 위한 프레임워크\n",
    "- OpenAIEmbeddings: 텍스트를 벡터로 변환\n",
    "- ElasticsearchStore: Elasticsearch를 벡터 저장소로 사용\n",
    "- ChatOpenAI: GPT 모델을 이용한 답변 생성\n",
    "- RetrievalQA: 검색-답변 체인 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시스템 환경 변수 관련 라이브러리\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Elasticsearch 연결을 위한 클라이언트 라이브러리\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "# LangChain 관련 라이브러리들\n",
    "from langchain.embeddings import OpenAIEmbeddings  # 텍스트를 벡터로 변환\n",
    "from langchain.vectorstores import ElasticsearchStore  # Elasticsearch 벡터 저장소\n",
    "from langchain.chat_models import ChatOpenAI  # ChatGPT 모델\n",
    "from langchain.chains import RetrievalQA  # 검색-답변 체인\n",
    "\n",
    "# .env 파일에서 환경 변수 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔌 2단계: Elasticsearch 연결\n",
    "\n",
    "Elasticsearch는 우리의 벡터 데이터베이스 역할을 합니다. \n",
    "문서의 벡터를 저장하고 검색하는데 사용됩니다.\n",
    "\n",
    "연결 시 필요한 정보:\n",
    "1. 서버 URL\n",
    "2. 사용자 이름\n",
    "3. 비밀번호\n",
    "\n",
    "이 정보들은 보안을 위해 .env 파일에 저장되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elasticsearch 클라이언트 객체 생성\n",
    "es = Elasticsearch(\n",
    "    # .env 파일에서 서버 URL 가져오기\n",
    "    os.getenv('ELASTICSEARCH_URL'),\n",
    "    \n",
    "    # 기본 인증 정보 설정\n",
    "    basic_auth=(\n",
    "        os.getenv('ELASTICSEARCH_USERNAME'),  # 사용자 이름\n",
    "        os.getenv('ELASTICSEARCH_PASSWORD')   # 비밀번호\n",
    "    ),\n",
    "    \n",
    "    # 개발 환경에서는 SSL 인증서 검증 비활성화\n",
    "    # 실제 운영 환경에서는 적절한 SSL 설정 필요\n",
    "    verify_certs=False\n",
    ")\n",
    "\n",
    "# 서버 연결 상태 확인\n",
    "if es.ping():  # ping() 메서드로 서버가 응답하는지 테스트\n",
    "    print(\"✅ Elasticsearch 연결 성공!\")\n",
    "else:\n",
    "    print(\"❌ Elasticsearch 연결 실패!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📝 3단계: 샘플 데이터 준비\n",
    "\n",
    "RAG 시스템을 테스트하기 위한 샘플 문서들을 준비합니다.\n",
    "실제 환경에서는 이 부분이 데이터베이스나 파일에서 문서를 불러오는 코드로 대체될 수 있습니다.\n",
    "\n",
    "여기서는 AI 관련 기초 개념들을 담은 간단한 문장들을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트용 샘플 문서 리스트\n",
    "# 각 문서는 AI 관련 주요 개념을 설명하는 한 문장으로 구성\n",
    "documents = [\n",
    "    \"인공지능(AI)은 인간의 학습능력, 추론능력, 지각능력을 컴퓨터로 구현하는 기술입니다.\",\n",
    "    \"머신러닝은 AI의 한 분야로, 데이터로부터 패턴을 학습하여 의사결정을 수행합니다.\",\n",
    "    \"딥러닝은 머신러닝의 한 종류로, 인공신경망을 사용하여 복잡한 패턴을 학습합니다.\",\n",
    "    \"자연어 처리(NLP)는 인간의 언어를 컴퓨터가 이해하고 처리할 수 있도록 하는 AI 기술입니다.\",\n",
    "    \"RAG(Retrieval-Augmented Generation)는 대규모 언어 모델의 지식을 외부 데이터로 보강하는 기술입니다.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔄 4단계: 벡터 저장소 설정\n",
    "\n",
    "이 단계에서는 다음과 같은 작업을 수행합니다:\n",
    "\n",
    "1. OpenAI의 임베딩 모델을 초기화하여 텍스트를 벡터로 변환할 준비\n",
    "2. Elasticsearch에 벡터를 저장할 인덱스 설정\n",
    "3. 샘플 문서들을 벡터로 변환하여 저장\n",
    "\n",
    "이렇게 저장된 벡터들은 나중에 질문과 관련된 문서를 검색할 때 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI의 임베딩 모델 초기화\n",
    "# 이 모델이 텍스트를 벡터로 변환하는 역할을 담당\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Elasticsearch 벡터 저장소 설정\n",
    "index_name = \"rag-demo\"  # 인덱스 이름 지정\n",
    "vector_store = ElasticsearchStore(\n",
    "    es_connection=es,  # Elasticsearch 연결 객체\n",
    "    index_name=index_name,  # 사용할 인덱스 이름\n",
    "    embedding=embeddings  # 사용할 임베딩 모델\n",
    ")\n",
    "\n",
    "# 준비된 문서들을 벡터로 변환하여 저장\n",
    "vector_store.add_texts(documents)\n",
    "print(f\"✅ {len(documents)}개의 문서가 성공적으로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🤖 5단계: RAG 시스템 구현\n",
    "\n",
    "이제 실제 RAG 시스템을 구현합니다. 이 시스템은 다음과 같이 동작합니다:\n",
    "\n",
    "1. 사용자가 질문을 입력\n",
    "2. 시스템이 질문과 관련된 문서를 검색\n",
    "3. ChatGPT가 검색된 문서를 참고하여 답변 생성\n",
    "\n",
    "이를 위해 LangChain의 RetrievalQA 체인을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatGPT 모델 초기화\n",
    "# temperature=0으로 설정하여 일관된 답변이 나오도록 함\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# RAG 체인 생성\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,  # 사용할 언어 모델\n",
    "    chain_type=\"stuff\",  # 검색된 문서를 하나의 컨텍스트로 결합\n",
    "    retriever=vector_store.as_retriever()  # 벡터 저장소를 검색기로 사용\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💬 6단계: 질문-답변 테스트\n",
    "\n",
    "마지막으로 구현된 RAG 시스템을 테스트합니다.\n",
    "시스템은 다음 과정을 거쳐 답변을 생성합니다:\n",
    "\n",
    "1. 질문을 벡터로 변환\n",
    "2. 벡터 유사도 검색으로 관련 문서 찾기\n",
    "3. 찾은 문서를 기반으로 ChatGPT가 답변 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트할 질문 설정\n",
    "question = \"RAG 기술이 무엇인가요?\"\n",
    "\n",
    "# RAG 체인을 통해 답변 생성\n",
    "# run() 메서드는 내부적으로 다음 과정을 수행:\n",
    "# 1. 질문을 벡터화\n",
    "# 2. 유사한 문서 검색\n",
    "# 3. ChatGPT로 답변 생성\n",
    "answer = qa_chain.run(question)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"질문: {question}\")\n",
    "print(f\"답변: {answer}\")\n",
    "\n",
    "# 다른 질문들도 시도해 보세요!\n",
    "# 예: \"머신러닝과 딥러닝의 차이는 무엇인가요?\"\n",
    "# 예: \"자연어 처리는 어떤 기술인가요?\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
