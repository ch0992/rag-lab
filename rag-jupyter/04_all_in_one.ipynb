{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG 시스템 - 통합 실행 노트북\n",
    "\n",
    "이 노트북은 RAG 시스템의 모든 기능을 한 번에 실행할 수 있습니다:\n",
    "1. 환경 설정 확인\n",
    "2. 문서 저장\n",
    "3. 문서 조회\n",
    "4. 질의-응답 생성\n",
    "\n",
    "## 1. 필요한 라이브러리 임포트 및 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 서버 설정\n",
    "CHROMA_HOST = \"localhost\"\n",
    "CHROMA_PORT = \"8090\"\n",
    "OLLAMA_HOST = \"localhost\"\n",
    "OLLAMA_PORT = \"11434\"\n",
    "\n",
    "# ChromaDB 설정\n",
    "CHROMA_SETTINGS = {\n",
    "    \"chroma_db_impl\": \"duckdb+parquet\",\n",
    "    \"persist_directory\": \"chroma\",\n",
    "    \"anonymized_telemetry\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 서버 상태 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_servers():\n",
    "    \"\"\"ChromaDB와 Ollama 서버 상태 확인\"\"\"\n",
    "    servers = {\n",
    "        'ChromaDB': f'http://{CHROMA_HOST}:{CHROMA_PORT}/api/v1/heartbeat',\n",
    "        'Ollama': f'http://{OLLAMA_HOST}:{OLLAMA_PORT}/api/tags'\n",
    "    }\n",
    "    \n",
    "    for name, url in servers.items():\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                print(f\"✅ {name} 서버가 정상적으로 실행 중입니다.\")\n",
    "            else:\n",
    "                print(f\"❌ {name} 서버에 연결할 수 없습니다. 상태 코드: {response.status_code}\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"❌ {name} 서버에 연결할 수 없습니다. 오류: {str(e)}\")\n",
    "\n",
    "# 서버 상태 확인\n",
    "check_servers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 임베딩 모델 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings():\n",
    "    \"\"\"한국어에 최적화된 임베딩 모델 생성\"\"\"\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"jhgan/ko-sbert-nli\",\n",
    "        model_kwargs={'device': 'cpu'},\n",
    "        encode_kwargs={'normalize_embeddings': True}\n",
    "    )\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 문서 저장 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_documents_in_chroma(documents: List[Dict[str, Any]], collection_name: str = \"rag_test\"):\n",
    "    \"\"\"문서를 벡터로 변환하여 ChromaDB에 저장\"\"\"\n",
    "    # 텍스트 분할 설정\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \"。\", \"！\", \"？\", \" \", \"\"]\n",
    "    )\n",
    "    \n",
    "    # 문서 처리\n",
    "    texts = []\n",
    "    metadatas = []\n",
    "    \n",
    "    for doc in documents:\n",
    "        chunks = text_splitter.split_text(doc['content'])\n",
    "        texts.extend(chunks)\n",
    "        \n",
    "        # 각 청크에 대한 메타데이터 생성\n",
    "        for _ in chunks:\n",
    "            metadata = {\n",
    "                'source': doc.get('source', 'unknown'),\n",
    "                'author': doc.get('author', 'unknown'),\n",
    "                'date': doc.get('date', 'unknown')\n",
    "            }\n",
    "            metadatas.append(metadata)\n",
    "    \n",
    "    # ChromaDB에 저장\n",
    "    embeddings = get_embeddings()\n",
    "    vectordb = Chroma(\n",
    "        collection_name=collection_name,\n",
    "        embedding_function=embeddings,\n",
    "        client_settings=CHROMA_SETTINGS,\n",
    "    )\n",
    "    \n",
    "    vectordb.add_texts(\n",
    "        texts=texts,\n",
    "        metadatas=metadatas\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ {len(texts)}개의 청크가 ChromaDB에 저장되었습니다.\")\n",
    "    return vectordb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 문서 조회 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vector_store(collection_name: str = \"rag_test\"):\n",
    "    \"\"\"ChromaDB에서 벡터 스토어 로드\"\"\"\n",
    "    try:\n",
    "        embeddings = get_embeddings()\n",
    "        vector_store = Chroma(\n",
    "            collection_name=collection_name,\n",
    "            embedding_function=embeddings,\n",
    "            client_settings=CHROMA_SETTINGS\n",
    "        )\n",
    "        print(f\"✅ 컬렉션 '{collection_name}'을 성공적으로 로드했습니다.\")\n",
    "        return vector_store\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 벡터 스토어 로드 중 오류 발생: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. LLM 질의-응답 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_ollama(prompt: str, context: str = \"\") -> str:\n",
    "    \"\"\"Ollama API를 사용하여 LLM 모델 호출\"\"\"\n",
    "    url = f\"http://{OLLAMA_HOST}:{OLLAMA_PORT}/api/generate\"\n",
    "    \n",
    "    system_prompt = \"\"\"\n",
    "    너는 주어진 컨텍스트를 기반으로 질문에 답변하는 도우미야.\n",
    "    다음 규칙을 반드시 따라야 해:\n",
    "    1. 컨텍스트에 있는 정보만 사용해서 답변해야 해\n",
    "    2. 컨텍스트에 없는 내용은 '주어진 정보에는 없습니다'라고 말해야 해\n",
    "    3. 답변은 한국어로 해야 해\n",
    "    4. 답변은 친절하고 자연스러운 어투를 사용해야 해\n",
    "    \"\"\"\n",
    "    \n",
    "    if context:\n",
    "        full_prompt = f\"{system_prompt}\\n\\n컨텍스트:\\n{context}\\n\\n질문: {prompt}\"\n",
    "    else:\n",
    "        full_prompt = f\"{system_prompt}\\n\\n질문: {prompt}\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, json={\n",
    "            \"model\": \"deepseek-r1:8b\",\n",
    "            \"prompt\": full_prompt,\n",
    "            \"stream\": False\n",
    "        })\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            return response.json()[\"response\"]\n",
    "        else:\n",
    "            return f\"❌ API 호출 실패: {response.status_code}\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        return f\"❌ 오류 발생: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rag_query(query: str, collection_name: str = \"rag_test\", k: int = 3):\n",
    "    \"\"\"벡터DB에서 질문에 대한 답변을 검색\"\"\"\n",
    "    # 벡터 스토어 로드\n",
    "    vector_store = load_vector_store(collection_name)\n",
    "    if not vector_store:\n",
    "        return \"❌ 벡터 스토어를 로드할 수 없습니다.\"\n",
    "    \n",
    "    try:\n",
    "        # 유사도 검색\n",
    "        results = vector_store.similarity_search_with_relevance_scores(query, k=k)\n",
    "        \n",
    "        if not results:\n",
    "            return \"관련된 문서를 찾을 수 없습니다.\"\n",
    "        \n",
    "        # 컨텍스트 구성\n",
    "        contexts = []\n",
    "        for doc, score in results:\n",
    "            if score < 0.5:  # 유사도가 낮은 문서는 제외\n",
    "                continue\n",
    "            contexts.append(f\"[유사도: {score:.2f}] {doc.page_content}\")\n",
    "        \n",
    "        context = \"\\n\\n\".join(contexts)\n",
    "        \n",
    "        # LLM으로 답변 생성\n",
    "        answer = query_ollama(query, context)\n",
    "        \n",
    "        return {\n",
    "            \"query\": query,\n",
    "            \"context\": context,\n",
    "            \"answer\": answer\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"❌ 오류 발생: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 예제 실행\n",
    "\n",
    "### 7.1 샘플 문서 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 문서\n",
    "sample_documents = [\n",
    "    {\n",
    "        \"content\": \"\"\"\n",
    "        한국의 봄은 3월부터 5월까지로, 꽃이 피고 날씨가 따뜻해지는 계절입니다.\n",
    "        특히 벚꽃이 피는 4월은 많은 사람들이 꽃구경을 가는 시기입니다.\n",
    "        봄에는 황사와 미세먼지가 있을 수 있지만, 새싹이 돋고 생명이 움트는 아름다운 계절입니다.\n",
    "        \"\"\",\n",
    "        \"source\": \"계절 설명서\",\n",
    "        \"author\": \"김계절\",\n",
    "        \"date\": \"2024-03-01\"\n",
    "    },\n",
    "    {\n",
    "        \"content\": \"\"\"\n",
    "        한국의 여름은 6월부터 8월까지입니다. 높은 기온과 습도가 특징이며,\n",
    "        장마철에는 집중적인 강우가 있습니다. 에어컨 사용이 늘어나고,\n",
    "        시원한 음식을 즐기는 계절입니다. 해수욕장이나 계곡으로 피서를 가는 것이 일반적입니다.\n",
    "        \"\"\",\n",
    "        \"source\": \"계절 설명서\",\n",
    "        \"author\": \"김계절\",\n",
    "        \"date\": \"2024-03-01\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 문서 저장\n",
    "vectordb = store_documents_in_chroma(sample_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 문서 조회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터 스토어 로드\n",
    "vector_store = load_vector_store()\n",
    "\n",
    "# 저장된 문서 수 확인\n",
    "if vector_store:\n",
    "    print(f\"저장된 문서 수: {vector_store._collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 질문하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 질문\n",
    "questions = [\n",
    "    \"한국의 봄은 어떤 특징이 있나요?\",\n",
    "    \"한국의 여름철 날씨는 어떤가요?\",\n",
    "    \"한국의 가을은 어떤 특징이 있나요?\"  # 데이터에 없는 내용\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"\\n질문: {question}\")\n",
    "    result = run_rag_query(question)\n",
    "    if isinstance(result, dict):\n",
    "        print(\"\\n답변:\")\n",
    "        print(result[\"answer\"])\n",
    "        print(\"\\n참고한 컨텍스트:\")\n",
    "        print(result[\"context\"])\n",
    "    else:\n",
    "        print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
